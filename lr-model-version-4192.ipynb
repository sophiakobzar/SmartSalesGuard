{"cells":[{"cell_type":"markdown","id":"02c4f2c2-3ee9-48b8-95fc-c5c9a3ef741e","metadata":{},"source":["# Track Machine Learning experiments and models\n"]},{"cell_type":"code","execution_count":null,"id":"82932090-f694-43cc-8f03-599a38fa11f3","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"transient":{"deleting":false}}},"outputs":[],"source":["df = spark.sql(\"SELECT * FROM lakehouseTraining.`superstore sales dataset` LIMIT 5\")\n","display(df)"]},{"cell_type":"code","execution_count":null,"id":"5f3864ff-cde6-4479-8d6d-33bad05ab358","metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"outputs":[],"source":["import pandas as pd\n","import re\n","from pyspark.sql import SparkSession\n","from sklearn.ensemble import IsolationForest\n","from sklearn.preprocessing import StandardScaler\n","import matplotlib.pyplot as plt\n","\n","# Initialize Spark session\n","spark = SparkSession.builder.appName(\"LakehouseTraining\").getOrCreate()\n","\n","# Enable Arrow optimization\n","spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n","\n","# Load the entire table into a Spark DataFrame\n","df = spark.sql(\"SELECT * FROM lakehouseTraining.`superstore sales dataset`\")\n","\n","# Convert Spark DataFrame to Pandas DataFrame\n","pandas_df = df.toPandas()\n","\n","# Clean the 'Sales' column by removing non-numeric characters\n","pandas_df['Sales'] = pandas_df['Sales'].apply(lambda x: re.sub(r'[^0-9.]', '', str(x)))\n","\n","# Convert 'Sales' and 'Profit' columns to numeric\n","pandas_df['Sales'] = pd.to_numeric(pandas_df['Sales'], errors='coerce')\n","pandas_df['Profit'] = pd.to_numeric(pandas_df['Profit'], errors='coerce')\n","\n","# Drop rows with NaN values\n","pandas_df.dropna(subset=['Sales', 'Profit'], inplace=True)\n","\n","# Normalize the data\n","scaler = StandardScaler()\n","pandas_df[['Sales', 'Profit']] = scaler.fit_transform(pandas_df[['Sales', 'Profit']])\n","\n","# Initialize the Isolation Forest model\n","iso_forest = IsolationForest(contamination=0.0125, random_state=42)\n","\n","# Fit the model\n","iso_forest.fit(pandas_df[['Sales', 'Profit']].values)\n","\n","# Predict anomalies using the same feature names\n","pandas_df['anomaly'] = iso_forest.predict(pandas_df[['Sales', 'Profit']].values)\n","\n","# Define normal and anomaly data points\n","normals = pandas_df[pandas_df['anomaly'] == 1]\n","anomalies = pandas_df[pandas_df['anomaly'] == -1]\n","\n","print(\"Number of anomalies detected:\", len(anomalies))\n","#print(anomalies)\n","\n","# Visualize the anomalies\n","plt.figure(figsize=(10, 6))\n","plt.scatter(normals['Sales'], normals['Profit'], c='blue', label='Normal', alpha=0.6)\n","plt.scatter(anomalies['Sales'], anomalies['Profit'], c='red', label='Anomaly', alpha=0.6)\n","plt.xlabel('Sales (Normalized)')\n","plt.ylabel('Profit (Normalized)')\n","plt.title('Anomaly Detection in Sales and Profit')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"]}],"metadata":{"dependencies":{"lakehouse":{"default_lakehouse":"41ef5cb9-27ec-4160-995c-48cc5e120d7f","default_lakehouse_name":"lakehouseTraining","default_lakehouse_workspace_id":"dc2b9547-cb65-4419-b6da-db854bb4bbff"}},"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.0"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"orig_nbformat":4,"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"synapse_widget":{"state":{},"version":"0.1"},"widgets":{}},"nbformat":4,"nbformat_minor":5}
